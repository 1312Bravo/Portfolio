<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Increase your chances of staying away from running injuries - HASR-TL – Urh Peček | Data Science Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-59898bd1c6b9d2bb783127feaa000c76.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-920f8b5b4a9e6fe8e930067d636556fa.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Urh Peček | Data Science Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects/training_log.html"> 
<span class="menu-text">Training Log</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/1312Bravo" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Increase your chances of staying away from running injuries - HASR-TL</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="idea" class="level3">
<h3 class="anchored" data-anchor-id="idea">Idea</h3>
<p>When training for endurance sports, our bodies adapt over time, and whether a workout is “hard” or “easy” on the body, depends on what we’ve been doing recently and historically. The goal is to define a simple metric that shows where we are with our current training compared to what we’ve been doing in the recent past. The purpose is to:</p>
<ul>
<li>see if we should reduce our training load so that we don’t overreach or risk injury,</li>
<li>oncrease it to match what our body has adapted to in the recent past, or</li>
<li>simply define where we are in the training cycle when taking the bigger picture into account.</li>
</ul>
<p>The idea of comparing current workload to past workload isn’t new. Sports science has long used the Acute:Chronic Workload Ratio (ACWR) to capture how today’s training compares to longer-term training history. But ACWR has well-known limitations: it usually relies on a single rolling average, and it can miss important context about peak efforts or variation in load. That’s where our approach comes in. We’ll further extend it into a more flexible and informative framework.</p>
</section>
<section id="selecting-the-metric" class="level3">
<h3 class="anchored" data-anchor-id="selecting-the-metric">Selecting the metric:</h3>
<p>To measure effort, we focus on <strong>Training Load</strong>, a metric that combines all other measures (options: distance, time, heart rate, pace or something else) into a single number. This also strongly coincides with the sport we are analyzing - trail running, where it is hard to judge intensity from speed or distance alone. We might talk more about Training Load in further blogs.</p>
<p>Training Load is provided from all of ours smart wearables and a practical way for making comparisons across very different sessions (and sports). We will use Garmin’s Training Load values provided in our training log.</p>
<p>The same approach can be applied to any other training metric. And by calculating values for each, we can see the story from multiple angles.</p>
</section>
<section id="deep-dive" class="level3">
<h3 class="anchored" data-anchor-id="deep-dive">Deep dive</h3>
<p>Let <span class="math inline">\(TL_i\)</span> be the training load of the day <span class="math inline">\(i\)</span>. Our goal is to define a metric that normalizes recent TL against historical. We can think of this in two complementary components:</p>
<ul>
<li><p><strong>Baseline (long term) adaptation</strong> - Load the body has been succesfully adapted to over a longer period, assuming this distribution is “safe”, disregarding recent acute load.</p>
<ul>
<li>Denoted as <span class="math inline">\(TL_{\text{baseline},t}\)</span>.</li>
<li>Computed over a long baseline window of <span class="math inline">\(N\)</span> days, excluding last <span class="math inline">\(n\)</span> days: <span class="math display">\[\mathcal{L}_t=\{TL_{t-(n+j)}\mid j=1,\dots, N\}\]</span></li>
<li>To give more importance to recent training within the baseline period, we assign weights decreasing with days: <span class="math display">\[w_j = \lambda^{j-1}, \quad 0 &lt; \lambda &lt;= 1, \quad j = 1, ..., N,\]</span> where more recent baseline days contribute more to defining the baseline load.</li>
</ul></li>
<li><p><strong>Recent training pattern</strong> - Load the body is currently being exposed to, capturing acute training load.</p>
<ul>
<li>Denoted as <span class="math inline">\(TL_{\text{recent},t}\)</span>.</li>
<li>Computed over a recent window of <span class="math inline">\(n\)</span> days: <span class="math display">\[\mathcal{R}_t=\{TL_{t-j}\mid j=1,\dots,n\}\]</span>.</li>
<li>This can also be weighted to emphasize the most recent sessions: <span class="math display">\[v_j = \lambda^{j-1}, \quad 0 &lt; \lambda &lt;= 1, \quad j = 1, ..., n\]</span></li>
</ul></li>
</ul>
<p>We define the <strong>parameters</strong> as:</p>
<ul>
<li>Baseline window: <span class="math inline">\(N = 90\)</span> days</li>
<li>Recent window: <span class="math inline">\(n = 14\)</span> days</li>
<li>Weight base <span class="math inline">\(\lambda\)</span> = <span class="math inline">\((0.5)^\frac{1}{31} = 0.978\)</span>, so weight halves approximately every 31 days.</li>
</ul>
<p>Additionaly: Because we aim to capture relative load patterns rather than total accumulated load, we normalize the weights so that they sum to 1. This ensures that the weighted, for example averages, for baseline and recent windows are directly comparable:</p>
<ul>
<li><span class="math inline">\(\overline{w}_j = \frac{w_j}{\sum_{k=1}^{N}w_k} \quad j = 1, ..., N\)</span></li>
<li><span class="math inline">\(\overline{v}_j = \frac{v_j}{\sum_{k=1}^{v}w_k} \quad j = 1, ..., v\)</span></li>
</ul>
<p><img src="saved_files/baseline_recent_weighting.png" class="click-zoom img-fluid"></p>
<p>Notes: By keeping the baseline and recent windows non-overlapping, we ensure that the baseline reflects only training the body has already adapted to, without being influenced by recent sessions that the body has not yet adjusted to. This allows us to identify increases in stress in the recent window that may pose a risk.</p>
<p>Dateset: We take into account all measured activities, regardless if it was real training or not (including hiking, swimming, easy cycling etc.) and treat total daily training load as daily sample.</p>
</section>
<section id="percentile-stratified-metric" class="level3">
<h3 class="anchored" data-anchor-id="percentile-stratified-metric">Percentile stratified metric</h3>
<p>In endurance sports, training days can be grouped into a few main types:</p>
<ul>
<li><strong>Easy sessions &amp; Rest days</strong> - used for recovery, aerobic base, and technique work. These make up roughly 55% of all sessions.</li>
<li><strong>Hard sessions</strong> - tempo, threshold, VO2max, or interval workouts. Typically around 30% of sessions.</li>
<li><strong>Long days</strong> - the occasional very long run, bike ride, or race that forms the extreme right tail of the distribution. About 15% of sessions.</li>
</ul>
<p>By tracking these session types separately we can see if:</p>
<ul>
<li>easy sessins are getting too long, too intense, or too rare, ensuring that we can perform well in harder workouts,</li>
<li>or recent hard sessions make up a reasonable portion of total sessions to allow sufficient recovery,</li>
<li>or recent long days are not too frequent or extreme.</li>
</ul>
<p>We will divide our days into these three categories based on Training Load values. Baseline window training load percentiles to define thresholds as this approach is individualized, automatic, and reproducible. These thresholds are then applied to both baseline and recent data.</p>
<ul>
<li>This ensures the baseline distribution reflects the training the body has already adapted to, providing a safe reference.</li>
<li>Recent sessions are evaluated relative to this safe baseline, so any increase in intensity, frequency, or duration signals higher acute load or potential risk.</li>
</ul>
<p>Formally, let <span class="math inline">\(\mathcal{Q}^w_p(\mathcal{L}_t)\)</span> be weighted <span class="math inline">\(p\)</span>-th quantile of the baseline window <span class="math inline">\(\mathcal{L}_t\)</span> using weights <span class="math inline">\(w_j\)</span> and define the baseline and recent buckets using baseline percentiles <span class="math inline">\(q^w_{70,t}\)</span> and <span class="math inline">\(q^w_{90,t}\)</span> as follows:</p>
<ul>
<li><strong>Easy sessions &amp; Rest days</strong>: Training loads falling below the weighted <span class="math inline">\(q_{low}\)</span> percentile of the window: <span class="math display">\[TL \leq q^w_{low,t}=Q^w_{low}(\mathcal{L}_t)\]</span></li>
<li><strong>Hard sessions</strong>: Training loads between the weighted <span class="math inline">\(q_{low}\)</span> and <span class="math inline">\(q_{high}\)</span> percentiles: <span class="math display">\[q^w_{70,t} &lt; TL \leq q^w_{high,t}=Q^w_{high}(\mathcal{L}_t)\]</span></li>
<li><strong>Long days</strong>: Training loads above the weighted 90th percentile: <span class="math display">\[TL &gt; q^w_{high,t}=Q^w_{high}(\mathcal{L}_t)\]</span></li>
</ul>
<p>Clarifying note: In order to perform any structured analysis, each session must be assigned to a bucket based on the percentile thresholds. This means that some sessions may fall into different buckets due to small differences in Training Load, even if their physiological impact is similar. So these categories should be interpreted with caution. Categories are a practical tool for analysis and a guide, rather than absolute labels. When interpreting them, consider the broader context.</p>
<p>Note on weighted percentiles: The weighted percentile represents the TL at which the cumulative sum of weights reaches the desired fraction of total weight. This accounts for the fact that more recent baseline sessions contribute more to the threshold.</p>
<p>Having defined these buckets, we summarize each bucket by the weighted average training load within, where we allow more recent training days to contribute more to the bucket averages. With this, we make the metric sensitive to shifts in the typical intensity of each type of session within the bucket.</p>
<p>Based on my training data (with a hardcoded mapping into the categories Rest, Easy, Hard, Long, and Other), the distribution of training loads and their descriptive values are as follows:</p>
<ul>
<li>Rest — 14% of days, TL = avg 0, SD 0</li>
<li>Easy — 47% of days, TL = avg 96, SD 43</li>
<li>Hard — 14% of days, TL = avg 190, SD 56</li>
<li>Long — 18% of days, TL = avg 218, SD 96</li>
<li>Other — 7% of days, TL = avg 130, SD 66</li>
</ul>
<p><img src="saved_files/training_type_distribution.png" class="click-zoom img-fluid"></p>
<p>Let <span class="math inline">\(w_j\)</span> be the weight of day <span class="math inline">\(j\)</span> in the baseline window <span class="math inline">\(\mathcal{L}_t\)</span> and <span class="math inline">\(v_j\)</span> be the weight of day <span class="math inline">\(j\)</span> in the recent window <span class="math inline">\(\mathcal{R}_t\)</span>. We then define the weighted averages within each bucket as:</p>
<p><strong>Baseline bucket weighted averages:</strong></p>
<p><span class="math display">\[\text{Easy}: \mu^w_{1,t} = \mathbb{E}_w[\,TL \mid TL \in \mathcal{L}_t,\; TL \le q^w_{low,t}\,]\]</span> <span class="math display">\[\text{Hard}: \mu^w_{2,t} = \mathbb{E}_w[\,TL \mid TL \in \mathcal{L}_t,\; q^w_{low,t} &lt; TL \le q^w_{high,t}\,]\]</span> <span class="math display">\[\text{Long}: \mu^w_{3,t} = \mathbb{E}_w[\,TL \mid TL \in \mathcal{L}_t,\; TL &gt; q^w_{high,t}\,]\]</span></p>
<p><strong>Recent bucket weighted averages:</strong></p>
<p><span class="math display">\[\text{Easy}: \nu^w_{1,t} = \mathbb{E}_w[\,TL \mid TL \in \mathcal{R}_t,\; TL \le q^w_{low,t}\,]\]</span> <span class="math display">\[\text{Hard}: \nu^w_{2,t} = \mathbb{E}_w[\,TL \mid TL \in \mathcal{R}_t,\; q^w_{low,t} &lt; TL \le q^w_{high,t}\,]\]</span> <span class="math display">\[\text{Long}: \nu^w_{3,t} = \mathbb{E}_w[\,TL \mid TL \in \mathcal{R}_t,\; TL &gt; q^w_{high,t}\,]\]</span></p>
<p>Where <span class="math inline">\(\mathbb{E}[\cdot]\)</span> denotes the empirical weighted mean <span class="math inline">\(\mathbb{E}_w[v] = \frac{\sum_{i=1}^nw_iv_i}{\sum_{i=1}^nw_i}\)</span> over the subset of training load values falling into the specified bucket.</p>
<p>In addition to the weighted averages, we can also track the proportion of sessions falling into each bucket in both the baseline and the recent window. Wheres the proportion of sessions falling into each bucket in Baseline window as pre-determined with quantiles, the number of easy, hard, and long sessions is not fixed once baseline thresholds are applied to recent training. For example, if the proportion of easy days decreases in recent window may signal insufficient recovery.</p>
<p>Formally, let: <span class="math display">\[\pi_{k,t}^{(b)} \quad \text{and} \quad \pi_{k,t}^{(r)}\]</span> denote proportions of sessions in bucket <span class="math inline">\(k = 1,2,3\)</span> in baseline and recent window respectively.</p>
<p><strong>Most recent Session Classification</strong></p>
<p>In addition to aggregated metrics, we can also assess each most recent individual session in the context of the baseline distribution. Specifically, for the most recent training session (e.g., the date of analysis), we can determine where its Training Load falls within the weighted baseline distribution.</p>
<p>This can be expressed as the weighted percentile (or baseline-relative quantile rank) of the session:</p>
<p><span class="math display">\[\phi_t = \frac{\sum_{j \in \mathcal{L}_t} w_j \,\mathbf{1}\{\,TL_j \leq TL_t^{(\text{recent})}\}}{\sum_{j \in \mathcal{L}_t} w_j}\]</span></p>
<p>This allows us to assign the session to one of the predefined buckets — Easy, Hard, or Long — using the same percentile thresholds derived from the baseline window:</p>
<p><span class="math display">\[
\text{Session classification} =
\begin{cases}
\text{Easy} &amp; \text{if } TL \le q^w_{\text{low},t} \\[2mm]
\text{Hard} &amp; \text{if } q^w_{\text{low},t} &lt; TL \le q^w_{\text{high},t} \\[1mm]
\text{Long} &amp; \text{if } TL &gt; q^w_{\text{high},t}
\end{cases}
\]</span></p>
<p>Also, as mentioned above, these classifications are meant as guidance; a more complete understanding comes from considering the weighted percentile values, which provide richer context on the session’s relative intensity.</p>
<p>By doing this, we can assess the acute characteristics of the latest session relative to what the athlete has already adapted to and estimate how individual session contributes to overall training stress. This information can then guide adjustments for upcoming workouts to ensure we stay on track with the training plan.</p>
</section>
<section id="history-aware-statified-relative---training-load-hasr-tl" class="level3">
<h3 class="anchored" data-anchor-id="history-aware-statified-relative---training-load-hasr-tl">History-Aware Statified Relative - Training Load (HASR-TL)</h3>
<p>Once training sessions are divided into the three percentile-based buckets, defined from the baseline window, we can combine them into a single, interpretable metric that reflects how recent training compares to the athlete’s long-term adaptation. The central idea is weighted aggregation, where each bucket contributes differently to the overall metric. By aggregating the per-bucket loads with appropriate weights, HASRTL produces a single number that reflects how the overall recent training load compares to the baseline adaptation.</p>
<p><strong>Weighted aggregation</strong></p>
<p>Let <span class="math inline">\(w_1, w_2, w_3\)</span> denote weights for easy, hard, and long sessions, respectively, with <span class="math display">\[w_1+w_2+w_3=1,\quad w_k\ge 0\]</span>. The baseline aggregate load is then: <span class="math display">\[TL_{\text{baseline},t} = w_1 \mu_{1,t} + w_2 \mu_{2,t} + w_3 \mu_{3,t}.\]</span> Similarly, the recent aggregate load is: <span class="math display">\[TL_{\text{recent},t} = w_1 \nu_{1,t} + w_2 \nu_{2,t} + w_3 \nu_{3,t}.\]</span></p>
<p>Finally, the <strong>History-Aware Stratified Relative Training Load (HASRTL)</strong> is defined as: <span class="math display">\[\Delta_t = \frac{TL_{\text{recent}}}{TL_{\text{baseline}}}.\]</span></p>
<p>Here, <span class="math inline">\(\Delta_t\)</span> expresses how the current (recent) training load compares to the long-term baseline. It can be interpreted as a percentage increase or decrease of recent load relative to baseline adaptation.</p>
<p>Since recent sessions are classified using baseline-defined buckets, <span class="math inline">\(\Delta_t\)</span> represents the relative training load compared to what the athlete has already adapted to, making it a robust measure of both increased stress and potential risk.</p>
<p><strong>Selection of weights <span class="math inline">\(w_1, w_2, w_3\)</span></strong></p>
<p>When defining the buckets weights, for our purpose, we have to consider the bucket’s contribution to adaptation and also their potential impact on injury risk. The weights should reflect the relative importance of bucket’s session type in promoting positive training effects while also accounting for their role in acute stress spikes that may increase the probability of injury.</p>
<ul>
<li>Easy sessions: As we defined them, they are frequent and involve low-intensity activities. They have low impact on both the adaptation and injury risk. Weight reflects their impact on training adaptation and injury risk.
<ul>
<li><span class="math inline">\(w_1 = 0.15\)</span></li>
</ul></li>
<li>Hard sessison: Less frequent but high-intensity activities that drive the adaptation and also impose higher acute loads that increase injury risk. Weight reflects their contribution to acute stress.
<ul>
<li><span class="math inline">\(w2 = 0.40\)</span></li>
</ul></li>
<li>Long sessison: They are rare but lead to high cumulative stress. They significantly contribute to adaptation and also pose a highest risk of injury. Weight reflects their peak stress contribution.
<ul>
<li><span class="math inline">\(w3: = 0.45\)</span></li>
</ul></li>
</ul>
<p>These weights are not directly measurable — they are largely subjective, based on expert knowledge, experience, and general principles of training load management rather than precise data.</p>
</section>
<section id="interpretation-bucket-level-diagnostics" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-bucket-level-diagnostics">Interpretation &amp; Bucket-level diagnostics</h3>
<p>Although <span class="math inline">\(\Delta_t\)</span> provides a clear mathematical ratio of recent to baseline training load, its practical interpretation is less straightforward — it is not always obvious when an increase or decrease becomes significant, risky, or indicative of detraining.</p>
<p><img src="saved_files/hasr_tl_full.png" class="click-zoom img-fluid"></p>
<p>The idea behind the HASR-TL metric is to summarize this relationship in a single number, but a deeper understanding comes from also examining the individual training buckets (e.g., easy, hard, long). Comparing these buckets within the baseline and recent windows, and between them, helps reveal where changes originate and adds richer context than the ratio alone.</p>
<p>By <strong>comparing bucket values within the same window</strong>, we gain insight to how well the training program is balanced across session types. This helps us check whether easy, hard, and long sessions are clearly distinct, or whether the loads are starting to blur together — which could reduce the effectiveness of the training. In practice, we calculate pairwise ratios of bucket weighted averages:</p>
<p><span class="math display">\[\zeta_{\mu_i, \mu_j} = \frac{\mu_{i,t}}{\mu_{j,t}} \quad \text{and} \quad \zeta_{\nu_i, \nu_j} = \frac{\nu_{i,t}}{\nu_{j,t}}, \quad i,j = 1,2,3, i \neq j\]</span></p>
<p>By monitoring these values, we can identify trends such as if easy vs.&nbsp;hard sessions are becoming too similar, which might indicate reduced stimulus diversity.</p>
<p><img src="saved_files/within_window_baseline_recent_comparison.png" class="click-zoom img-fluid"></p>
<p>To understand which types of sessions are driving changes in overall load and what type of training have we been emphasizing lately, we <strong>compare values each bucket between recent and baseline windows</strong>.</p>
<p><span class="math display">\[\delta_{k,t} = \frac{\nu_{k,t}}{\mu_{k,t}}, \quad k = 1,2,3\]</span></p>
<p>This ratio focuses on the intensity or load of sessions of a given type, independent of how often these sessions occur.</p>
<p><img src="saved_files/within_bucket_easy_hard_comparison.png" class="click-zoom img-fluid"></p>
<p>For example, a rise in <span class="math inline">\(\delta_{1,t}\)</span> might indicate that easy sessions are becoming more demanding relative to the baseline. Whereas a decrease in <span class="math inline">\(\delta_{3,t}\)</span> suggests that long sessions are less intense, long possibly absent.</p>
<p>In contrast, to see how the distribution of session types is shifting, we <strong>compare the proportion of each session type in the recent window relative to the baseline</strong>:</p>
<p><span class="math display">\[\rho_{k,t} = \frac{\pi_{k,t}^{(r)}}{\pi_{k,t}^{(b)}}, \quad k=1,2,3\]</span></p>
<p>This ratio captures frequency changes, not intensity.</p>
<p><img src="saved_files/bucket_proportion_easy_hard_comparison.png" class="click-zoom img-fluid"></p>
<p>For example, <span class="math inline">\(\rho_{1,t} &lt; 1\)</span> may indicate that recovery-oriented easy days are becoming too rare, while <span class="math inline">\(\rho_{3,t} &gt; 1\)</span> suggests long sessions are occurring more frequently, than the body is adapted to.</p>
<p>Together, these diagnostics offer a comprehensive view of training composition and its evolution and form the foundation for interpreting the aggregated HASRTL metric. However, <strong>the key question remains</strong>: how large a change is meaningful, risky, or indicative of under or over-training? These interpretive challenges will be explored in the next chapter.</p>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>These statistics are similar to activity statistics presented in the Data blog, daily calculated and available for review and possible analysis in Google sheets. They are under <a href="https://docs.google.com/spreadsheets/d/1o5Y9_AM_8baj5DnB2AE9nYXU_ZSPsyFW6VjRbljSWIw/edit?gid=2140406364#gid=2140406364" target="_blank">Activity Log file - HASR-TL sheet</a>.</p>
<div class="project-link-container">
    <i class="fab fa-github"></i>
    <span> You can find the full code for this section, along with the analyses, which is then easily integrated into the <code>src/main.py</code> script, on my Github repository under the
    <a href="https://github.com/1312Bravo/TrainingPeaks_customLog/tree/main/analysis/history_aware_relative_stratified_training_load" target="_blank"> history_aware_relative_stratified_training_load</a>
     folder.</span>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>