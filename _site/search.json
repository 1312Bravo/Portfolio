[
  {
    "objectID": "projects/training_log.html",
    "href": "projects/training_log.html",
    "title": "Training Log",
    "section": "",
    "text": "I see everything in life through the prism of mathematics or statistics. It’s no different with sports, especially running (or cycling). This blog will be a place where I combine my passion for endurance sports with professional background in data science. Just as I enjoy solving equations or structuring data models at work, I enjoy applying that same curiosity to my own training. Training logs, race preparation, and performance modeling — all of these can be enriched by numbers, models, and careful analysis.\nAnother motivation behind starting this blog is that I recently began working with a coach. That gave me an extra push to look deeper into how we are structuring the training, how I’m progressing, and to better understand the “why” behind what we’re doing. It’s not only about following workouts but also about making sense of the bigger picture, seeing how the plan unfolds, and how the numbers reflect adaptation and improvement.\nNumbers, when put into context, tell a story: whether I’m adapting, improving, or stepping into risky territory. That’s why each blog post will focus on a specific question and explore how mathematical thinking can bring clarity—whether it’s about training load, heart rate, distance, or other aspects of performance. This blog is my way of sharing that journey—where mountains, trails, and bikes meet mathematics, analytics, and a touch of artistry.\n\n    \n     Check out the full \n     GitHub repository \n    for this project\n\n\nTrack Your Training Smarter - Data\nKeep all your training and daily metrics in one place without lifting a finger. With a Python pipeline connecting Garmin Connect to Google Sheets, your workouts and daily metrics update automatically every day. The result: a complete, always-current record that makes analysis, trend spotting, and make data-driven decisions precise. 2025-08-20\n\n\nIncrease your chances of staying away from running injuries - HASR-TL\nPut recent training into context by comparing it with your history. Give yourself a clearer picture of whether you’re pushing into new territory or staying within safe limits. The goal is to help you understand your training load better, catch signs of overtraining early, reduce the risk of injuries or just define where in the training cycle you are. 2025-09-15"
  },
  {
    "objectID": "projects/training_log/data.html",
    "href": "projects/training_log/data.html",
    "title": "Track Your Training Smarter - Data",
    "section": "",
    "text": "Before diving into analysis, it’s worth showing where the numbers come from. I wanted a consistent and automated way to capture my training.\nTwo main datasets are daily updated and live in Google Sheets. Having the data in this format makes it easy to explore manually, but also gives me a flexible base for deeper analysis. I provide only a static sample of data logs.\n\nTraining Log – workouts with different metrics, including distance, duration, elevation, heart rate.\nDaily Log – day-level statistics, such as steps, sleep, resting heart rate, recovery time, and other daily metrics.\n\nThe statistics come from the Garmin Connect API. A Python script fetches both activity and daily statistics, and then pushes them into the Google Sheets. Some metrics are raw Garmin values, while others are adjusted or calculated. Statistics that are captured in sheets can also evolve over time as we discover new metrics or further analyze training. So, some of the statistics in the sheet can also be presented in details in other blog posts.\nThe script is run each morning and spreadsheets expand by one more day of history (yesterday’s data), keeping the logs synchronized without manual work. The script can also loop through multiple accounts if provided.\nThe script relies two key integrations:\n\nGarmin Connect API – fetch activities and health metrics.\n\nfrom garminconnect import Garmin  \n\ngarminClient = Garmin(garmin_email, garmin_password)  \ngarminClient.login()\ngarminClient.get_activities_by_date(date_from, date_to)\n\nGoogle Sheets API – store and update logs.\n\nimport gspread\nfrom google.oauth2.service_account import Credentials  \n\ndrive_credentials = Credentials.from_service_account_file(\n    \"googleDrive_secrets.json\",  \n    scopes=[\"https://www.googleapis.com/auth/spreadsheets\",  \n            \"https://www.googleapis.com/auth/drive\"]  \n)\n\ngoogleDrive_client = gspread.authorize(drive_credentials)  \ngoogleDrive_client.open(user_dailyLogFilename)\nOf course, logging in requires credentials (emails, passwords, API keys). They are not hardcoded, but live in a .env file locally and as GitHub Secrets in the cloud, keeping sensitive content secure while still accessible for automation.\n\n    \n     You can find the full code for this part, which is then easily implemented into src/main.py script, on my Github repository under the\n     basic_daily_activity_statistics\n     folder."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Urh Peček",
    "section": "",
    "text": "Hi, I’m Urh Peček! A data scientist and lifelong learner, fascinated by how numbers, models, and analytics help us make sense of the world. On this site, I share projects, experiments, and stories that spark my curiosity.\nThese posts come from my own independent interests—questions I want to explore, datasets I find intriguing, or challenges that push me to think differently. Each project may be explored through multiple blog-style posts, each focusing on a different aspect, insight, or experiment. This allows me to break complex topics into digestible pieces while following a clear narrative. Each one is an opportunity to apply mathematics, statistics, and analytical thinking in a way that’s both rigorous and creative.\nI aim to make insights clear, actionable, and occasionally even artistic. I share not just results, but the thought process, experiments, and learning along the way. My hope is that every post inspires you to look at problems differently, question assumptions, and maybe spark your own experiments."
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Urh Peček",
    "section": "Featured Projects",
    "text": "Featured Projects\n\nTraining Log\nAnalysing training data with Python and Garmin data."
  },
  {
    "objectID": "projects/training_log/hasr_tl.html",
    "href": "projects/training_log/hasr_tl.html",
    "title": "Increase your chances of staying away from running injuries - HASR-TL",
    "section": "",
    "text": "Idea\nWhen training for endurance sports, our bodies adapt over time, and whether a workout is “hard” or “easy” on the body, depends on what we’ve been doing recently and historically. The goal is to define a simple metric that shows where we are with our current training compared to what we’ve been doing in the recent past. The purpose is to:\n\nsee if we should reduce our training load so that we don’t overreach or risk injury,\noncrease it to match what our body has adapted to in the recent past, or\nsimply define where we are in the training cycle when taking the bigger picture into account.\n\nThe idea of comparing current workload to past workload isn’t new. Sports science has long used the Acute:Chronic Workload Ratio (ACWR) to capture how today’s training compares to longer-term training history. But ACWR has well-known limitations: it usually relies on a single rolling average, and it can miss important context about peak efforts or variation in load. That’s where our approach comes in. We’ll further extend it into a more flexible and informative framework.\n\n\nSelecting the metric:\nTo measure effort, we focus on Training Load, a metric that combines all other measures (options: distance, time, heart rate, pace or something else) into a single number. This also strongly coincides with the sport we are analyzing - trail running, where it is hard to judge intensity from speed or distance alone. We might talk more about Training Load in further blogs.\nTraining Load is provided from all of ours smart wearables and a practical way for making comparisons across very different sessions (and sports). We will use Garmin’s Training Load values provided in our training log.\nThe same approach can be applied to any other training metric. And by calculating values for each, we can see the story from multiple angles.\n\n\nDeep dive\nLet \\(TL_i\\) be the training load of the day \\(i\\). Our goal is to define a metric that normalizes recent TL against historical. We can think of this in two complementary components:\n\nBaseline (long term) adaptation - Load the body has been succesfully adapted to over a longer period, assuming this distribution is “safe”, disregarding recent acute load.\n\nDenoted as \\(TL_{\\text{baseline},t}\\).\nComputed over a long baseline window of \\(N\\) days, excluding last \\(n\\) days: \\[\\mathcal{L}_t=\\{TL_{t-(n+j)}\\mid j=1,\\dots, N\\}\\]\nTo give more importance to recent training within the baseline period, we assign weights decreasing with days: \\[w_j = \\lambda^{j-1}, \\quad 0 &lt; \\lambda &lt;= 1, \\quad j = 1, ..., N,\\] where more recent baseline days contribute more to defining the baseline load.\n\nRecent training pattern - Load the body is currently being exposed to, capturing acute training load.\n\nDenoted as \\(TL_{\\text{recent},t}\\).\nComputed over a recent window of \\(n\\) days: \\[\\mathcal{R}_t=\\{TL_{t-j}\\mid j=1,\\dots,n\\}\\].\nThis can also be weighted to emphasize the most recent sessions: \\[v_j = \\lambda^{j-1}, \\quad 0 &lt; \\lambda &lt;= 1, \\quad j = 1, ..., n\\]\n\n\nWe define the parameters as:\n\nBaseline window: \\(N = 90 days\\)\nRecent window: \\(n = 14 days\\)\nWeight base \\(\\lambda\\) = \\((0.5)^\\frac{1}{31} = 0.978\\), so weight halves approximately every 31 days.\n\nAdditionaly: Because we aim to capture relative load patterns rather than total accumulated load, we normalize the weights so that they sum to 1. This ensures that the weighted, for example averages, for baseline and recent windows are directly comparable:\n\n\\(\\overline{w}_j = \\frac{w_j}{\\sum_{k=1}^{N}w_k} \\quad j = 1, ..., N\\)\n\\(\\overline{v}_j = \\frac{v_j}{\\sum_{k=1}^{v}w_k} \\quad j = 1, ..., v\\)\n\n\nNotes: By keeping the baseline and recent windows non-overlapping, we ensure that the baseline reflects only training the body has already adapted to, without being influenced by recent sessions that the body has not yet adjusted to. This allows us to identify increases in stress in the recent window that may pose a risk.\nDateset: We take into account all measured activities, regardless if it was real training or not (including hiking, swimming, easy cycling etc.) and treat total daily training load as daily sample.\n\n\nPercentile stratified metric\nIn endurance sports, training days can be grouped into a few main types:\n\nEasy sessions & Rest days - used for recovery, aerobic base, and technique work. These make up roughly 55% of all sessions.\nHard sessions - tempo, threshold, VO2max, or interval workouts. Typically around 30% of sessions.\nLong days - the occasional very long run, bike ride, or race that forms the extreme right tail of the distribution. About 15% of sessions.\n\nBased on my training data (with a hardcoded mapping into the categories Rest, Easy, Hard, Long, and Other), the distribution of training loads and their descriptive values are as follows:\n\nRest — 14% of days, TL = avg 0, SD 0\nEasy — 47% of days, TL = avg 96, SD 43\nHard — 14% of days, TL = avg 190, SD 56\nLong — 18% of days, TL = avg 218, SD 96\nOther — 7% of days, TL = avg 130, SD 66\n\n\nBy tracking these session types separately we can see if:\n\neasy sessins are getting too long, too intense, or too rare, ensuring that we can perform well in harder workouts,\nor recent hard sessions make up a reasonable portion of total sessions to allow sufficient recovery,\nor recent long days are not too frequent or extreme.\n\nWe will divide our days into these three categories based on Training Load values. Baseline window training load percentiles to define thresholds as this approach is individualized, automatic, and reproducible. These thresholds are then applied to both baseline and recent data.\n\nThis ensures the baseline distribution reflects the training the body has already adapted to, providing a safe reference.\nRecent sessions are evaluated relative to this safe baseline, so any increase in intensity, frequency, or duration signals higher acute load or potential risk.\n\nFormally, let \\(\\mathcal{Q}^w_p(\\mathcal{L}_t)\\) be weighted \\(p\\)-th quantile of the baseline window \\(\\mathcal{L}_t\\) using weights \\(w_j\\) and define the baseline and recent buckets using baseline percentiles \\(q^w_{70,t}\\) and \\(q^w_{90,t}\\) as follows:\n\nEasy sessions: Training loads falling below the weighted \\(q_{low}\\) percentile of the window: \\[TL \\leq q^w_{low,t}=Q^w_{low}(\\mathcal{L}_t)\\]\nHard sessions: Training loads between the weighted \\(q_{low}\\) and \\(q_{high}\\) percentiles: \\[q^w_{70,t} &lt; TL \\leq q^w_{high,t}=Q^w_{high}(\\mathcal{L}_t)\\]\nLong days: Training loads above the weighted 90th percentile: \\[TL &gt; q^w_{high,t}=Q^w_{high}(\\mathcal{L}_t)\\]\n\nNote on weighted percentiles: The weighted percentile represents the TL at which the cumulative sum of weights reaches the desired fraction of total weight. This accounts for the fact that more recent baseline sessions contribute more to the threshold.\nHaving defined these buckets, we summarize each bucket by the weighted average training load within, where we allow more recent training days to contribute more to the bucket averages. With this, we make the metric sensitive to shifts in the typical intensity of each type of session within the bucket.\nLet \\(w_j\\) be the weight of day \\(j\\) in the baseline window \\(\\mathcal{L}_t\\) and \\(v_j\\) be the weight of day \\(j\\) in the recent window \\(\\mathcal{R}_t\\). We then define the weighted averages within each bucket as:\nBaseline bucket weighted averages:\n\nEasy: \\(\\mu^w_{1,t} = \\mathbb{E}_w[\\,TL \\mid TL \\in \\mathcal{L}_t,\\; TL \\le q^w_{low,t}\\,]\\)\nHard: \\(\\mu^w_{2,t} = \\mathbb{E}_w[\\,TL \\mid TL \\in \\mathcal{L}_t,\\; q^w_{low,t} &lt; TL \\le q^w_{high,t}\\,]\\)\nLong: \\(\\mu^w_{3,t} = \\mathbb{E}_w[\\,TL \\mid TL \\in \\mathcal{L}_t,\\; TL &gt; q^w_{high,t}\\,]\\)\n\nRecent bucket weighted averages:\n\nEasy: \\(\\nu^w_{1,t} = \\mathbb{E}_w[\\,TL \\mid TL \\in \\mathcal{R}_t,\\; TL \\le q^w_{low,t}\\,]\\)\nHard: \\(\\nu^w_{2,t} = \\mathbb{E}_w[\\,TL \\mid TL \\in \\mathcal{R}_t,\\; q^w_{low,t} &lt; TL \\le q^w_{high,t}\\,]\\)\nLong: \\(\\nu^w_{3,t} = \\mathbb{E}_w[\\,TL \\mid TL \\in \\mathcal{R}_t,\\; TL &gt; q^w_{high,t}\\,]\\)\n\nWhere \\(\\mathbb{E}[\\cdot]\\) denotes the empirical weighted mean \\(\\mathbb{E}_w[v] = \\frac{\\sum_{i=1}^nw_iv_i}{\\sum_{i=1}^nw_i}\\) over the subset of training load values falling into the specified bucket.\nIn addition to the weighted averages, we can also track the proportion of sessions falling into each bucket in both the baseline and the recent window, as the number of easy, hard, and long sessions is not fixed once baseline thresholds are applied to recent training. For example, if the proportion of easy days decreases in recent window may signal insufficient recovery.\nFormally, let: \\(\\pi_{k,t}^{(b)}\\) and \\(\\pi_{k,t}^{(r)}\\) denote proportions of sessions in bucket \\(k = 1,2,3\\) in baseline and recent window respectively."
  }
]